{
 "cells": [
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "import pandas as pd\nimport numpy as np\nfrom fredapi import Fred\nimport yfinance as yf\nfrom pathlib import Path\nimport json\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.preprocessing import PolynomialFeatures, StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport plotly.graph_objs as go\nimport plotly.io as pio\nimport logging\n\npio.renderers.default = 'notebook'\n\nclass Config:\n    \"\"\"Configuration management\"\"\"\n    def __init__(self, config_path='configs.json'):\n        self.config_path = Path(config_path)\n        self.cache_folder = Path('cache')\n        self.cache_folder.mkdir(exist_ok=True)\n        \n    def load_api_key(self):\n        if not self.config_path.exists():\n            raise FileNotFoundError(f\"Config file not found: {self.config_path}\")\n        with open(self.config_path, 'r') as f:\n            return json.load(f)['api_key']\n\n\nclass FredData:\n    def __init__(self, features=None, cache_folder='cache'):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.folder = Path(cache_folder)\n        self.folder.mkdir(exist_ok=True)\n        \n        # Handle features input\n        if features is None:\n            self.features = []\n        elif isinstance(features, str):\n            self.features = [features]\n        elif isinstance(features, list):\n            self.features = features\n        else:\n            raise TypeError(\"features must be None, str, or list\")\n        \n        self.fred = None\n        \n    def connect(self, api_key):\n        \"\"\"Initialize Fred connection\"\"\"\n        self.fred = Fred(api_key)\n        \n    def get_data(self):\n        if not self.fred:\n            raise RuntimeError(\"Fred API not connected. Call connect() first.\")\n            \n        if not self.features:\n            self.logger.warning(\"No features specified\")\n            return False\n            \n        success = True\n        for feature in self.features:\n            path = self.folder / f'{feature}.csv'\n            if path.exists():\n                self.logger.info(f'Data for {feature} found in cache.')\n                continue\n                \n            try:\n                self.logger.info(f'Fetching data for {feature}...')\n                series = self.fred.get_series(feature)\n                series.name = feature\n                series.to_csv(path)\n                self.logger.info(f'Data for {feature} successfully downloaded.')\n            except Exception as e:\n                self.logger.warning(f'Could not download {feature}: {e}')\n                success = False\n                \n        return success\n\n\nclass TickerData:\n    def __init__(self, ticker, cache_folder='cache', interval='1d'):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.folder = Path(cache_folder)\n        self.ticker = ticker if isinstance(ticker, str) else None\n        self.interval = interval\n        \n        if self.ticker is None:\n            raise ValueError(\"ticker must be a string\")\n        \n    def get_data(self):\n        path = self.folder / f'{self.ticker}_ohlc_{self.interval}.csv'\n        \n        if path.exists():\n            self.logger.info(f'Data for {self.ticker} found in cache.')\n            return True\n            \n        try:\n            self.logger.info(f'Fetching data for {self.ticker}...')\n            df = yf.download(\n                tickers=self.ticker,\n                interval=self.interval,\n                period='max',\n                progress=False,\n                auto_adjust=True\n            )\n            \n            if df.empty:\n                raise ValueError(f\"No data returned for {self.ticker}\")\n                \n            df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n            df.to_csv(path)\n            self.logger.info(f'Data for {self.ticker} successfully downloaded.')\n            return True\n            \n        except Exception as e:\n            self.logger.error(f'Could not download {self.ticker}: {e}')\n            return False\n\n\nclass DataAnalyzer:\n    def __init__(self, ticker, feature, cache_folder='cache'):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.folder = Path(cache_folder)\n        \n        if not isinstance(ticker, str) or not isinstance(feature, str):\n            raise TypeError(\"ticker and feature must be strings\")\n            \n        self.ticker = ticker\n        self.feature = feature\n    \n    def _load_csv(self, path):\n        \"\"\"Helper to load and validate CSV data\"\"\"\n        if not path.exists():\n            self.logger.warning(f'{path.name} does not exist.')\n            return pd.DataFrame()\n            \n        try:\n            df = pd.read_csv(path, index_col=0, parse_dates=True).dropna()\n            if df.empty:\n                self.logger.warning(f'{path.name} is empty.')\n            return df\n        except Exception as e:\n            self.logger.error(f'Error loading {path.name}: {e}')\n            return pd.DataFrame()\n    \n    def _get_ticker(self):\n        path = self.folder / f'{self.ticker}_ohlc_1d.csv'\n        return self._load_csv(path)\n        \n    def _get_feature(self):\n        path = self.folder / f'{self.feature}.csv'\n        return self._load_csv(path)\n    \n    def analyze(self):\n        \"\"\"Analyze correlation between ticker and feature\"\"\"\n        tdf = self._get_ticker()\n        fdf = self._get_feature()\n        \n        if tdf.empty or fdf.empty:\n            self.logger.warning(f'Cannot analyze {self.ticker} vs {self.feature}: insufficient data')\n            return None, None\n        \n        # Use Close price for ticker\n        tdf = tdf['Close'].to_frame(name=self.ticker)\n        \n        # Merge on date index\n        df = pd.concat([tdf, fdf], join='inner', axis=1)\n        \n        if df.empty:\n            self.logger.warning(f'No overlapping dates for {self.ticker} and {self.feature}')\n            return None, None\n        \n        # Normalize\n        scaler = StandardScaler()\n        normalized = pd.DataFrame(\n            scaler.fit_transform(df),\n            columns=df.columns,\n            index=df.index\n        )\n        \n        # Calculate correlation\n        corr = normalized[self.ticker].corr(normalized[self.feature])\n        \n        return normalized, corr\n\n\nclass EconomicPredictor:\n    def __init__(self, lag=7, poly_degree=2, alpha=0.1):\n        self.logger = logging.getLogger(self.__class__.__name__)\n        self.lag = lag\n        self.poly_degree = poly_degree\n        self.alpha = alpha\n        self.model = Ridge(alpha=self.alpha)\n        self.scaler = StandardScaler()\n        self.poly = PolynomialFeatures(degree=self.poly_degree)\n        self.feature_names = []\n        \n    def prepare_data(self, feature_dfs, ticker_name, corr_threshold=0.3):\n        \"\"\"Prepare features and target from analyzed data\"\"\"\n        valid_features = []\n        \n        for df, corr in feature_dfs:\n            if df is None or abs(corr) < corr_threshold:\n                continue\n            valid_features.append(df)\n        \n        if not valid_features:\n            raise ValueError(\"No features meet correlation threshold\")\n        \n        # Combine all valid features\n        combined = pd.concat(valid_features, axis=1, join='inner')\n        \n        # Remove duplicate columns (keep first occurrence)\n        combined = combined.loc[:, ~combined.columns.duplicated()]\n        \n        # Separate target (ticker) from features\n        if ticker_name not in combined.columns:\n            raise ValueError(f\"Ticker {ticker_name} not found in combined data\")\n            \n        y = combined[ticker_name].copy()\n        X = combined.drop(columns=[ticker_name])\n        \n        # Store feature names for plotting\n        self.feature_names = X.columns.tolist()\n        \n        # Apply lag: predict future y using past X\n        # Shift y forward (or X backward) by lag periods\n        y_future = y.shift(-self.lag).dropna()\n        X_aligned = X.loc[y_future.index]\n        \n        self.logger.info(f\"Prepared data shape: X={X_aligned.shape}, y={y_future.shape}\")\n        \n        # Create polynomial features\n        X_poly = self.poly.fit_transform(X_aligned)\n        \n        return X_poly, y_future.values, X_aligned, y_future\n    \n    def train(self, X, y, test_size=0.35):\n        \"\"\"Train model with time series split\"\"\"\n        # Ensure y is 1D\n        if len(y.shape) > 1:\n            y = y.flatten()\n            \n        split_idx = int(len(X) * (1 - test_size))\n        X_train, X_test = X[:split_idx], X[split_idx:]\n        y_train, y_test = y[:split_idx], y[split_idx:]\n        \n        self.logger.info(f\"Training on {len(X_train)} samples, testing on {len(X_test)}\")\n        self.logger.info(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n        self.logger.info(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n        \n        # Fit model\n        self.model.fit(X_train, y_train)\n        \n        # Predict\n        y_pred = self.model.predict(X_test)\n        \n        # Ensure both are 1D for metrics\n        y_test = y_test.flatten()\n        y_pred = y_pred.flatten()\n        \n        # Metrics\n        mse = mean_squared_error(y_test, y_pred)\n        r2 = r2_score(y_test, y_pred)\n        \n        self.logger.info(f\"MSE: {mse:.4f}, RÂ²: {r2:.4f}\")\n        \n        return {\n            'y_test': y_test,\n            'y_pred': y_pred,\n            'mse': mse,\n            'r2': r2,\n            'split_idx': split_idx\n        }\n\n\ndef plot_feature_correlations(analyzed_data, features_dict, symbol):\n    \"\"\"Plot correlation scatter plots for feature selection\"\"\"\n    fig = go.Figure()\n    fig.update_layout(template='presentation')\n    \n    for (df, corr), (name, code) in zip(analyzed_data, features_dict.items()):\n        if df is not None and not df.empty:\n            fig.add_trace(\n                go.Scatter(\n                    x=df[symbol],\n                    y=df[code],\n                    mode='markers',\n                    name=f'{name} (r={corr:.2f})',\n                    marker=dict(size=5),\n                    hovertemplate='<b>%{x:.2f}<br>%{y:.2f}</b>',\n                    opacity=0.8\n                )\n            )\n    \n    fig.update_layout(\n        xaxis_title=f'{symbol} (Normalized)',\n        yaxis_title='Feature (Normalized)',\n        font=dict(size=11),\n        title=dict(\n            text='Feature & Ticker Relationship',\n            font=dict(size=17, style='italic')\n        ),\n        hovermode='closest'\n    )\n    \n    return fig\n\n\ndef plot_model_evaluation(results, dates=None):\n    \"\"\"Plot actual vs predicted values\"\"\"\n    fig = go.Figure()\n    \n    x_axis = dates if dates is not None else np.arange(len(results['y_test']))\n    \n    # Actual values\n    fig.add_trace(\n        go.Scatter(\n            x=x_axis,\n            y=results['y_test'],\n            mode='lines',\n            name='Actual',\n            line=dict(color='blue', width=2),\n            hovertemplate='<b>Actual: %{y:.3f}</b><extra></extra>'\n        )\n    )\n    \n    # Predicted values\n    fig.add_trace(\n        go.Scatter(\n            x=x_axis,\n            y=results['y_pred'],\n            mode='lines',\n            name='Predicted',\n            line=dict(color='red', width=2, dash='dash'),\n            hovertemplate='<b>Predicted: %{y:.3f}</b><extra></extra>'\n        )\n    )\n    \n    # Add metrics annotation\n    fig.add_annotation(\n        xref='paper', yref='paper',\n        x=0.02, y=0.98,\n        text=f\"RÂ² = {results['r2']:.3f}<br>MSE = {results['mse']:.4f}\",\n        showarrow=False,\n        bgcolor='rgba(255, 255, 255, 0.8)',\n        bordercolor='black',\n        borderwidth=1,\n        font=dict(size=12)\n    )\n    \n    fig.update_layout(\n        template='presentation',\n        title=dict(\n            text='Machine Learning Model Evaluation',\n            font=dict(style='italic', size=17)\n        ),\n        font=dict(size=11),\n        xaxis_title='Time Index' if dates is None else 'Date',\n        yaxis_title='Ticker (Normalized)',\n        hovermode='x unified'\n    )\n    \n    return fig\n\n\ndef plot_residuals(results):\n    \"\"\"Plot residuals to assess model performance\"\"\"\n    residuals = results['y_test'] - results['y_pred']\n    \n    fig = go.Figure()\n    \n    # Residual scatter\n    fig.add_trace(\n        go.Scatter(\n            x=results['y_pred'],\n            y=residuals,\n            mode='markers',\n            name='Residuals',\n            marker=dict(size=6, color='purple', opacity=0.6),\n            hovertemplate='<b>Predicted: %{x:.3f}<br>Residual: %{y:.3f}</b><extra></extra>'\n        )\n    )\n    \n    # Zero line\n    fig.add_hline(\n        y=0, \n        line_dash=\"dash\", \n        line_color=\"red\",\n        annotation_text=\"Zero Error\"\n    )\n    \n    fig.update_layout(\n        template='presentation',\n        title=dict(\n            text='Residual Plot',\n            font=dict(style='italic', size=17)\n        ),\n        xaxis_title='Predicted Values',\n        yaxis_title='Residuals',\n        font=dict(size=11),\n        showlegend=False\n    )\n    \n    return fig\n\n\ndef plot_feature_importance(model, feature_names):\n    \"\"\"Plot feature importance from model coefficients\"\"\"\n    if hasattr(model, 'coef_'):\n        # For polynomial features, only show original features (first n coefficients)\n        n_features = len(feature_names)\n        coeffs = model.coef_[0][:n_features] if len(model.coef_.shape) > 1 else model.coef_[:n_features]\n        \n        fig = go.Figure()\n        \n        fig.add_trace(\n            go.Bar(\n                x=feature_names,\n                y=np.abs(coeffs),\n                marker=dict(color=coeffs, colorscale='RdBu', showscale=True),\n                hovertemplate='<b>%{x}<br>Coefficient: %{y:.3f}</b><extra></extra>'\n            )\n        )\n        \n        fig.update_layout(\n            template='presentation',\n            title=dict(\n                text='Feature Importance (Absolute Coefficients)',\n                font=dict(style='italic', size=17)\n            ),\n            xaxis_title='Features',\n            yaxis_title='|Coefficient|',\n            font=dict(size=11),\n            showlegend=False\n        )\n        \n        return fig\n    \n    return None\n\n\ndef main():\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    \n    # Configuration\n    symbol = 'SPY'\n    features = {\n        'Consumer Price Index': 'CPIAUCSL',\n        'Producer Price Index': 'PPIACO',\n        'Unemployment Rate': 'UNRATE',\n        'Job Openings': 'PAYEMS',\n        'Interest Rate': 'FEDFUNDS',\n        'Consumer Sentiment': 'UMCSENT',\n        'PCE Price Index': 'PCEPI',\n        'Core PCE (Non-Seasonal)': 'PCEPILFE'\n    }\n    \n    # Load config and get data\n    config = Config()\n    api_key = config.load_api_key()\n    \n    # Fetch economic data\n    fred_data = FredData(list(features.values()))\n    fred_data.connect(api_key)\n    fred_data.get_data()\n    \n    # Fetch ticker data\n    ticker_data = TickerData(symbol)\n    ticker_data.get_data()\n    \n    # Analyze correlations\n    print(\"\\n\" + \"=\"*60)\n    print(\"CORRELATION ANALYSIS\")\n    print(\"=\"*60)\n    analyzed_data = []\n    for name, code in features.items():\n        analyzer = DataAnalyzer(symbol, code)\n        normalized_df, corr = analyzer.analyze()\n        if normalized_df is not None:\n            print(f\"{name:30s} ({code:10s}): r = {corr:6.3f}\")\n            analyzed_data.append((normalized_df, corr))\n        else:\n            analyzed_data.append((None, 0))\n    \n    # Plot 1: Feature Correlations\n    print(\"\\nðŸ“Š Plotting feature correlations...\")\n    fig1 = plot_feature_correlations(analyzed_data, features, symbol)\n    fig1.show()\n    \n    # Train model\n    print(\"\\n\" + \"=\"*60)\n    print(\"MODEL TRAINING\")\n    print(\"=\"*60)\n    predictor = EconomicPredictor(lag=7, poly_degree=2, alpha=0.1)\n    X, y, X_original, y_original = predictor.prepare_data(analyzed_data, symbol, corr_threshold=0.3)\n    results = predictor.train(X, y, test_size=0.22)\n    \n    # Get dates for x-axis\n    test_dates = y_original.index[results['split_idx']:]\n    \n    # Plot 2: Model Evaluation\n    print(\"\\nðŸ“Š Plotting model evaluation...\")\n    fig2 = plot_model_evaluation(results, dates=test_dates)\n    fig2.show()\n    \n    # Plot 3: Residuals\n    print(\"\\nðŸ“Š Plotting residuals...\")\n    fig3 = plot_residuals(results)\n    fig3.show()\n    \n    # Plot 4: Feature Importance\n    if predictor.feature_names:\n        print(\"\\nðŸ“Š Plotting feature importance...\")\n        fig4 = plot_feature_importance(predictor.model, predictor.feature_names)\n        if fig4:\n            fig4.show()\n    \n    # Summary\n    print(\"\\n\" + \"=\"*60)\n    print(\"MODEL PERFORMANCE SUMMARY\")\n    print(\"=\"*60)\n    print(f\"RÂ² Score:     {results['r2']:.4f}\")\n    print(f\"MSE:          {results['mse']:.4f}\")\n    print(f\"RMSE:         {np.sqrt(results['mse']):.4f}\")\n    print(f\"Train Size:   {results['split_idx']}\")\n    print(f\"Test Size:    {len(results['y_test'])}\")\n    print(\"=\"*60)\n\n\nif __name__ == '__main__':\n    main()\n",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
